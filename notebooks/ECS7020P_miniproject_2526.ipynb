{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50604f75-b5b8-4b1d-a7ef-e8a1c577cf6b",
   "metadata": {},
   "source": [
    "# ECS7020P - Song Prediction From Humming & Whistling Recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e634b7c8-c1c9-4522-9689-3d45cb06218f",
   "metadata": {},
   "source": [
    "# 1 Author\n",
    "\n",
    "**Student Name:** Oscar Gallegos\n",
    "\n",
    "**Student ID:** 250851715"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5362fbd-1a8f-42f2-8868-6b2d7acd8973",
   "metadata": {},
   "source": [
    "# 2 Problem Formulation\n",
    "\n",
    "## 2.1 Goal\n",
    "\n",
    "Build a supervised machine learning model that, given a single 10 seconds audio recording of a person humming or whistling, predicts which song (from the dataset) the recording corresponds to.\n",
    "\n",
    "## 2.2 Formal Statement\n",
    "\n",
    "Let ùëã be the space of audio records of fixed duration (10 s) and Y = {1,‚Ä¶,C} the set of song labels. From a training set $\\{(x_i, y_i)\\}_{i=1}^N$ drawn IID from an unknown distribution, learn a mapping that generalizes to unseen samples. \n",
    "\n",
    "$$\n",
    "f_{\\theta} : X \\to Y\n",
    "$$\n",
    "\n",
    "This means:\n",
    "\n",
    "* The model takes an audio clip (x) and outputs a predicted song label (yÃÇ).\n",
    "\n",
    "The learning objective is to minimize empirical classification error (or equivalently maximize accuracy) on a validation set. Secondary goals include:\n",
    "\n",
    "* **Robustness to pitch variation:** A model still predicts the right song even if someone hums 2 semitones higher.\n",
    "* **Robustness to tempo variation:** If someone hums the melody too fast or too slow, the model still recognizes it.\n",
    "* **Interpretability of learned features:** Understanding what the model is using to make decisions, i.e. pitch shape, rhythm, MFCCs, mel patterns.\n",
    "\n",
    "## 2.3 Inputs & Outputs\n",
    "\n",
    "* **Input:** 10 seconds audio clip (.wav format). Preprocessing will convert this to one or more feature representations.\n",
    "* **Output:** Discrete song ID (Class label)\n",
    "\n",
    "## 2.4 Challenges and Relevance of Problem\n",
    "\n",
    "Identifying a song from a short humming or whistling recording presents several challenges that make the task both difficult and interesting. Because the audio contains only the melodic line without instrumentation, lyrics or harmony, the model must rely almost entirely on pitch contour and temporal structure. This is further complicated by substantial variability between recordings: different users may hum at different tempos, in different keys, with varying degrees of vibrato, background noise, or pitch stability. These factors create high intra-class variability, making it harder for a model to learn consistent patterns.\n",
    "\n",
    "In addition, the dataset is relatively small (approximately 400‚Äì800 samples), which increases the risk of overfitting, especially for deep learning models. This makes the problem a valuable opportunity to explore feature engineering, regularisation, and robust validation strategies. The task also suffers from label ambiguity because short 10-second segment may not capture uniquely identifying melodic segments; many popular songs share similar short melodic fragments.\n",
    "\n",
    "Together, these challenges highlight why this problem is relevant for machine learning research: it requires designing models that emphasize relative melodic movement rather than absolute pitch, implementing data augmentation to address variability, and evaluating how different feature representations influence classification performance.\n",
    "\n",
    "## 2.5 Success Criteria and Evaluation\n",
    "\n",
    "**Primary metric** \n",
    "\n",
    "* Accuracy on a validation set: the percentage of validation samples for which the model predicts the correct song.\n",
    "\n",
    "\n",
    "**Secondary metrics**\n",
    "\n",
    "* Top-k accuracy: Many songs have similar melodic fragments. The model may confuse them but still get the correct song in its top few predictions. Useful when melodies are short or ambiguous.\n",
    "  \n",
    "* Confusion matrix: A table showing which songs are mistaken for which other songs. It helps to understand patterns of mistakes, not just the error rate.\n",
    "\n",
    "* Per-class precision: to measure how reliable the model‚Äôs predictions are when it labels a clip as a specific song.\n",
    "* Per-class recall: to evaluate how well the model manages to find all examples of each song, especially those that are harder to recognize.\n",
    "* Per-class macro F1: to obtain a balanced measure that treats every song equally, ensuring that classes with fewer samples are not overshadowed by larger ones.\n",
    "\n",
    "* Model assessment: Besides numeric scores, we will analyze common confusions and error cases, and inspect which features (e.g., MFCCs vs. pitch contour) contribute most.\n",
    "\n",
    "## 2.6 Constraints and Assumptions\n",
    "\n",
    "This project assumes that all audio recordings in the dataset have a fixed duration of 10 seconds; in cases where this is not true, the clips will be padded or truncated to ensure consistent input length. Additionally, we assume that the provided labels accurately reflect the true song identity and treat them as ground truth throughout training and evaluation. Finally, we assume that the training and validation samples are independent and identically distributed (IID), meaning that each sample is drawn independently from the same underlying distribution. This assumption allows the validation performance to serve as an unbiased estimate of generalization, although in practice small datasets and possible similarities between recordings may limit this ideal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b02c98-f1eb-43be-8d3f-36502106bb0b",
   "metadata": {},
   "source": [
    "# 3 Methodology\n",
    "\n",
    "This project approaches the task of predicting the song identity from a 10 second hum or whistle by designing a supervised multi-class classification pipeline. The methodology consists of:\n",
    "\n",
    "1. Defining training task\n",
    "2. Defining validation task\n",
    "3. Selecting appropriate performance metrics\n",
    "4. Specifying auxiliary tasks that support model development such as feature extraction and exploratory data analysis.\n",
    "\n",
    "\n",
    "## 3.1 Training Task\n",
    "\n",
    "The training task is to learn a classifier function $f_{\\theta}$ parameterized by ${\\theta}$ (model parameters), which maps audio recordings $x \\in X$ to song labels $y \\in Y = \\{1, \\ldots, C\\}$. The classifier is trained on a dataset of labelled audio samples, where each instance consists of a 10 second waveform and its corresponding song identifier. \n",
    "\n",
    "The parameters ${\\theta}$ are optimized to minimize empirical classification loss. For most models, this corresponds to the cross-entropy loss:\n",
    "\n",
    "$$\n",
    "L(\\theta) = -\\frac{1}{N} \\sum_{i=1}^{N} \\log p_{\\theta}(y_i \\mid x_i)\n",
    "$$\n",
    "\n",
    "Preprocessing and feature extraction (e.g., log-mel spectrograms or MFCC coefficients) are treated as an integral part of the training task to ensure that the classifier receives consistent and informative representations.\n",
    "\n",
    "\n",
    "## 3.2 Validation Task\n",
    "\n",
    "To assess generalization, the dataset is partitioned into independent training and validation datasets. The validation task evaluates the trained classifier on unseen audio recordings, providing an unbiased estimate of performance. All hyperparameter choices (e.g., feature configuration, model capacity, learning rate, regularization) will be selected based on validation results. The validation set is strictly held out and never used during training.\n",
    "\n",
    "We ensure that the data split mimics the IID assumption by randomly assigning samples to each set, while noting any potential limitations such as class imbalance or similarity between samples. The validation task therefore supports model selection, early stopping, and error analysis.\n",
    "\n",
    "## 3.3 Performance Metrics\n",
    "\n",
    "The primary metric used to evaluate model performance is classification accuracy, defined as the proportion of validation samples whose predicted label matches the ground truth:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{1}{M} \\sum_{j=1}^{M} \\mathbf{1}\\{ f_\\theta(x_j) = y_j \\}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* M: Total number of samples in the validation set\n",
    "* $x_j$: The input of the ùëó-th example.\n",
    "* $y_j$: The true label (correct song ID) for sample ùëó.\n",
    "* $f_{\\theta}(\\cdot)$: The trained classifier with parameters Œ∏.\n",
    "\n",
    "However, accuracy alone may overlook class imbalance or patterns of misclassification. Thus, we additionally consider:\n",
    "\n",
    "* Confusion matrix, to visualize which songs the model tends to confuse.\n",
    "* Per-class precision, recall, and F1 score, to understand performance across all labels.\n",
    "* Top-k accuracy, useful when melodic similarity leads multiple songs to share similar contours.\n",
    "\n",
    "These metrics support a deeper analysis of model behaviour beyond a single scalar score.\n",
    "\n",
    "\n",
    "## 3.4 Auxiliary Tasks\n",
    "\n",
    "Several auxiliary tasks are included to improve the overall robustness of the pipeline:\n",
    "\n",
    "1. Exploratory data analysis: inspecting waveform statistics, label distribution, and audio examples.\n",
    "2. Feature engineering: comparing multiple representations (e.g., MFCCs, log-mel spectrograms) to evaluate which contain the most informative melodic structure.\n",
    "3. Data preprocessing: normalizing audio amplitudes, resampling to a consistent sample rate, and padding/truncating to fixed duration.\n",
    "4. Data augmentation: introducing pitch shifts, time-stretching, or noise injection to simulate variability in human humming.\n",
    "\n",
    "These tasks provide insights and help mitigate overfitting given the limited dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671dd93-48b9-4e2e-b72d-0e9f1608cd4f",
   "metadata": {},
   "source": [
    "# 4 Implemented ML Prediction Pipelines\n",
    "\n",
    "This project explores a multi-stage machine learning pipeline designed to predict the identity of a song from a 10-second hum or whistle. The three pipelines implemented follow a structured flow consisting of two stages:\n",
    "\n",
    "1. Transformation stage that converts raw waveforms into suitable features\n",
    "2. Model stage that performs multi-class classification\n",
    "   \n",
    "* Each stage transforms the intermediate data into a new representation, progressively moving from raw audio to song predictions. The pipeline is modular, enabling each component to be analysed and evaluated independently, while also allowing alternative approaches to be compared.\n",
    "\n",
    "The general structure for all pipelines is:\n",
    "\n",
    "Raw Audio Waveform ‚Üí Preprocessing ‚Üí Feature Extraction ‚Üí ML Model ‚Üí Predicted Song Label\n",
    "\n",
    "* For each pipeline, the input is the raw waveform sampled from the dataset, and the output is a class label corresponding to one of the possible songs. Intermediate data structures include processed waveforms (float arrays), time‚Äìfrequency features (MFCC matrices or log-mel spectrograms), and probability vectors output by the classifier.\n",
    "\n",
    "* Three different pipelines are created by selecting different feature representations and models. All pipelines share the same structure but differ in their specific components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98fe33-de1e-4a76-8dd3-f60221d90d2d",
   "metadata": {},
   "source": [
    "## 4.1 Transformation Stage\n",
    "\n",
    "The transformation stage converts the raw audio waveform into a numerical feature representation suitable for machine learning models.\n",
    "\n",
    "* **Input:** One-dimensional audio signal (time-domain waveform)\n",
    "* **Output:** Two-dimensional or one-dimensional feature tensor, depending on the chosen representation.\n",
    "\n",
    "An ensemble stage was not implemented in this study primarily due to the relatively small dataset size. Ensemble methods typically require multiple well-trained, diverse models to achieve performance gains, and with limited training samples per song, individual models risk overfitting. Adding an ensemble under these conditions would likely amplify overfitting rather than improve generalization. Therefore, we focused on evaluating and comparing single-model performance to obtain clearer insights into how each modeling approach handles the hummed and whistled melody classification task.\n",
    "\n",
    "The entire transformation stage flow consists of the following:\n",
    "\n",
    "Raw waveform ‚Üí preprocessing ‚Üí feature extraction ‚Üí feature tensor\n",
    "\n",
    "Preprocessing, which is performed prior to feature extraction to ensure consistency across all samples, consists of: \n",
    "\n",
    "* Resampling: Converts all audio clips to a common sampling rate, ensuring that frequency-related features are comparable across samples.\n",
    "* Amplitude Normalization: Scales the signal to a consistent loudness level so that models focus on pitch and timbre rather than volume differences.\n",
    "* Trimming/padding to a fixed length (10 seconds): Trimming and padding adjust every audio clip to the same duration, allowing all feature tensors to have uniform shapes required by machine learning models\n",
    "\n",
    "Two main feature extraction approaches are explored:\n",
    "\n",
    "1. MFCCs (Mel-Frequency Cepstral Coefficients): MFCCs capture the coarse spectral envelope of the audio and are widely used in speech and humming recognition. They produce a 2D matrix of size (number frames √ó number coefficients).\n",
    "For classical machine learning models (Logistic Regression and Random Forest), this matrix is flattened into a 1D feature vector, as these models require fixed-length vectors as input.\n",
    "\n",
    "2. Log-Mel Spectrograms: Log-mel spectrograms retain richer time‚Äìfrequency detail and are more suitable for modelling melodic structure. They produce a dense 2D representation, similar to an image. This representation is kept in 2D form for the Convolutional Neural Network (CNN), since CNNs naturally operate on image-like inputs.\n",
    "\n",
    "The reason for these transformations is because:\n",
    "\n",
    "* Humming contains pitch contours and harmonic structures that are not sufficiently captured by raw waveforms. This is well suited for Log-mel spectrograms, since they preserve harmonic structure, timbre, and pitch contours very well.\n",
    "* Most successful audio classification models rely on time‚Äìfrequency representations that resemble images, making them suitable for convolutional neural networks. Log-mel spectrograms give those representations.\n",
    "* MFCCs provide a compact representation that can be flattened into a 1-dimensional feature vector, making them computationally efficient and well-suited for algorithms such as logistic regression, random forests, and SVMs that require fixed-length inputs.‚Äù\n",
    "\n",
    "In detail, the three pipelines flow consists of:\n",
    "\n",
    "1. **Logistic Regression Model:** Raw waveform ‚Üí preprocessing ‚Üí MFCCs ‚Üí flattened 1D feature vector\n",
    "2. **Random Forest Model:** Raw waveform ‚Üí preprocessing ‚Üí MFCCs ‚Üí flattened 1D feature vector\n",
    "3. **Convolutional Neural Network Model:** Raw waveform ‚Üí preprocessing ‚Üí Log-Mel Spectrograms ‚Üí 2D feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ee81d-8577-40eb-a023-e794ef48867d",
   "metadata": {},
   "source": [
    "## 4.2 Model Stage\n",
    "\n",
    "Several machine learning models are explored in order to compare their strengths and weaknesses when applied to hum-based song classification. \n",
    "\n",
    "* **Input:** A feature tensor (flattened MFCC vector or 2D log-mel spectrogram)\n",
    "* **Output:** A probability vector across the set of possible song labels.\n",
    "* **Intermediate data:** Model-specific parameters and internal activations (e.g., tree splits, linear weights, convolutional feature maps)\n",
    "\n",
    "Three different types of classifiers are implemented:\n",
    "\n",
    "1. **Logistic Regression:** A simple linear classifier used as a baseline. Although limited in capacity, it serves as a sanity check by establishing whether the extracted features contain enough discriminative information for classification. \n",
    "\n",
    "    * **Input:** 1D vector of length ùêπ (flattened MFCCs).\n",
    "    * **Output:** Probability vector over song labels.\n",
    "    * **Operation:** It applies a linear transformation followed by softmax.\n",
    "    * **Intermediate Data:** linear logits ùëäùë•+ùëè ‚Üí softmax ‚Üí **probability vector**\n",
    "\n",
    "2. **Random Forest Classifier:** A non-linear ensemble of decision trees. Random forests are robust to noisy feature vectors, require minimal tuning, and provide a comparison point against linear baselines.\n",
    "\n",
    "    * **Input:** 1D vector (same MFCC flattened features as logistic regression)\n",
    "    * **Output:** Probability vector over classes.\n",
    "    * **Operation:** Each tree outputs a class vote; votes are averaged.\n",
    "    * **Intermediate Data:** tree decisions + aggregated votes ‚Üí class probabilities ‚Üí **probability vector**\n",
    "          \n",
    "3. **Neural Network Model:** CNNs exploit the ‚Äúimage-like‚Äù structure of spectrograms and can learn hierarchical patterns such as pitch contours, local harmonics, and timbral cues.\n",
    "\n",
    "    * **Input:** 2D feature matrix\n",
    "    * **Output:** Probability vector over song identities\n",
    "    * **Operation:** convolution ‚Üí nonlinearity ‚Üí pooling ‚Üí dense layers ‚Üí softmax\n",
    "    * **Intermediate Data:** convolutional feature maps ‚Üí pooled maps ‚Üí dense activations ‚Üí softmax ‚Üí **probability vector**\n",
    "\n",
    "The combination of simple (logistic regression), mid-complexity (random forest), and deep (CNN) models enables comparison under realistic constraints such as:\n",
    "\n",
    "* Limited dataset size\n",
    "* Variable humming quality\n",
    "* Overlapping melodic contours between songs\n",
    "* Differences in how each model uses time‚Äìfrequency structure\n",
    "\n",
    "This allows a complete analysis of how model complexity impacts performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9c1f9-2369-4d64-8bc8-83cb250ffa6d",
   "metadata": {},
   "source": [
    "# 5 Dataset\n",
    "\n",
    "This section describes the datasets used to train and evaluate the humming/whistling-based song classification models.  \n",
    "All datasets are derived from the *MLEnd Hums and Whistles II* waveform collections, which contain raw `.wav` files following the naming convention:\n",
    "\n",
    "`[Participant ID]_[type of recording]_[interpretation number]_[song]`.wav\n",
    "\n",
    "As an example: S1_hum_2_Necessities.wav\n",
    "\n",
    "From this filename we extract:\n",
    "- **Participant ID** ‚Üí `S1`  \n",
    "- **Recording Type** ‚Üí `hum` (or `whistle`)  \n",
    "- **Interpretation number** ‚Üí `2`  \n",
    "- **Song label** ‚Üí `Necessities`  \n",
    "\n",
    "Two raw datasets are provided:\n",
    "\n",
    "### **5.1 Dataset A ‚Äî MLEndHWII_sample_400**\n",
    "- 400 audio samples  \n",
    "- Contains humming and whistling clips  \n",
    "- 1.09 GB \n",
    "- Used to prototype preprocessing, feature extraction, and modeling  \n",
    "- Smaller size makes debugging easier  \n",
    "- Potential limitation: fewer samples per class ‚Üí risk of overfitting  \n",
    "\n",
    "### **5.2 Dataset B ‚Äî MLEndHWII_sample_800**\n",
    "- 800 audio samples  \n",
    "- All 400 samples from Dataset A are included  \n",
    "- 2.19 GB  \n",
    "- Used to train the final models  \n",
    "- Increased class coverage and variation  \n",
    "- Limitation: computational cost increases  \n",
    "\n",
    "### **Derived Datasets**\n",
    "From Dataset B (800 samples) we construct:\n",
    "\n",
    "### **5.3 Training Dataset**\n",
    "- 80% of samples  \n",
    "- Stratified by **song** to maintain balanced class proportions  \n",
    "- Ensures samples are IID by randomizing participants and interpretation number  \n",
    "\n",
    "### **5.4 Validation Dataset**\n",
    "- 20% of samples  \n",
    "- Used only for evaluation  \n",
    "- No participant overlap constraints (dataset too small to split by identity)  \n",
    "- Limitation: Some participant leakage is possible\n",
    "\n",
    "### Summary of Dataset Pipeline\n",
    "- Raw `.wav` files loaded  \n",
    "- Metadata parsed from filenames  \n",
    "- Data indexed into a dataframe  \n",
    "- Stratified split into Train/Validation  \n",
    "- These datasets feed into the preprocessing ‚Üí feature extraction ‚Üí model pipelines\n",
    "\n",
    "\n",
    "**Ensuring IID Samples and Dataset Independence**\n",
    "\n",
    "To approximate IID conditions, all splitting is performed randomly and stratified by the song label, ensuring that each class appears in the same proportions in both training and validation sets. Randomisation across participants, interpretation numbers, and recording types helps prevent systematic patterns that could bias the models.\n",
    "\n",
    "However, the dataset has structural constraints that limit true independence. Multiple recordings from the same participant, with similar humming/whistling habits, appear in both the training and validation sets. This creates a risk of participant leakage, where the model may partially learn person-specific features (timbre, microphone distance, humming style) instead of purely learning song characteristics. Therefore, although the split is statistically IID, it is not completely identity independent.\n",
    "\n",
    "This limitation means that validation accuracy may slightly overestimate real-world performance, especially on unseen singers. The analysis later in the report will take this into account when interpreting results.\n",
    "\n",
    "\n",
    "Firstly, we will import the necessary libraries to begin with our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a185e269-1819-4f80-9603-aa804f75992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ml Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cf6c7-2d33-4af3-9ad8-fc1d1e29d010",
   "metadata": {},
   "source": [
    "The following helper function decodes each filename into structured metadata, allowing us to build a complete labeled dataset directly from the .wav files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0be856-5201-42b9-a3de-c0cd7ae25913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    \n",
    "    name = os.path.splitext(filename)[0]  # removes .wav\n",
    "    parts = name.split(\"_\", 3)            # split into 4 parts\n",
    "\n",
    "    if len(parts) < 4:\n",
    "        return None  # skips malformed filenames\n",
    "\n",
    "    participant_id, rec_type, inter, song = parts\n",
    "    \n",
    "    return {\"participant_id\": participant_id,\n",
    "            \"recording_type\": rec_type,\n",
    "            \"interpretation_number\": inter,\n",
    "            \"song\": song,\n",
    "            \"filename\": filename \n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0756dda0-1c60-47cf-be88-f5802c6bfce9",
   "metadata": {},
   "source": [
    "This block builds the dataset index, which will be the dataframe that will represent the entire dataset. It xtracts metadata from file names, attaches full paths, and builds the complete dataset DataFrame used for training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a90b00c5-dbc8-43df-8cd8-e17456874955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(dataset_path):\n",
    "    records = []\n",
    "\n",
    "    for f in os.listdir(dataset_path):\n",
    "        if f.lower().endswith(\".wav\"):\n",
    "            parsed = parse_filename(f)\n",
    "            if parsed:\n",
    "                parsed[\"filepath\"] = os.path.join(dataset_path, f)\n",
    "                records.append(parsed)\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3b7ee-3ff6-4aa8-8d73-8d991962ea50",
   "metadata": {},
   "source": [
    "## 5.1 Dataset A ‚Äî MLEndHWII_sample_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5704946-a4a0-4bab-8235-9930a18fa04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset A: 400 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>recording_type</th>\n",
       "      <th>interpretation_number</th>\n",
       "      <th>song</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S100</td>\n",
       "      <td>hum</td>\n",
       "      <td>2</td>\n",
       "      <td>Married</td>\n",
       "      <td>S100_hum_2_Married.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_400\\S100_hum_2_Marrie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S100</td>\n",
       "      <td>whistle</td>\n",
       "      <td>2</td>\n",
       "      <td>Happy</td>\n",
       "      <td>S100_whistle_2_Happy.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_400\\S100_whistle_2_Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S100</td>\n",
       "      <td>whistle</td>\n",
       "      <td>2</td>\n",
       "      <td>RememberMe</td>\n",
       "      <td>S100_whistle_2_RememberMe.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_400\\S100_whistle_2_Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S101</td>\n",
       "      <td>hum</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>S101_hum_1_Married.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_400\\S101_hum_1_Marrie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S101</td>\n",
       "      <td>hum</td>\n",
       "      <td>2</td>\n",
       "      <td>Friend</td>\n",
       "      <td>S101_hum_2_Friend.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_400\\S101_hum_2_Friend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id recording_type interpretation_number        song  \\\n",
       "0           S100            hum                     2     Married   \n",
       "1           S100        whistle                     2       Happy   \n",
       "2           S100        whistle                     2  RememberMe   \n",
       "3           S101            hum                     1     Married   \n",
       "4           S101            hum                     2      Friend   \n",
       "\n",
       "                        filename  \\\n",
       "0         S100_hum_2_Married.wav   \n",
       "1       S100_whistle_2_Happy.wav   \n",
       "2  S100_whistle_2_RememberMe.wav   \n",
       "3         S101_hum_1_Married.wav   \n",
       "4          S101_hum_2_Friend.wav   \n",
       "\n",
       "                                            filepath  \n",
       "0  ../data/MLEndHWII_sample_400\\S100_hum_2_Marrie...  \n",
       "1  ../data/MLEndHWII_sample_400\\S100_whistle_2_Ha...  \n",
       "2  ../data/MLEndHWII_sample_400\\S100_whistle_2_Re...  \n",
       "3  ../data/MLEndHWII_sample_400\\S101_hum_1_Marrie...  \n",
       "4  ../data/MLEndHWII_sample_400\\S101_hum_2_Friend...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_400 = \"../data/MLEndHWII_sample_400\"\n",
    "df_400 = build_index(path_400)\n",
    "print(\"Dataset A:\", len(df_400), \"samples\")\n",
    "df_400.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26fa92-e493-420f-831b-60afd6846e81",
   "metadata": {},
   "source": [
    "## 5.2 Dataset B ‚Äî MLEndHWII_sample_800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9fd659f-f136-4c42-8ca3-2fbf52cbc425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset B: 800 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>recording_type</th>\n",
       "      <th>interpretation_number</th>\n",
       "      <th>song</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S100</td>\n",
       "      <td>hum</td>\n",
       "      <td>2</td>\n",
       "      <td>Married</td>\n",
       "      <td>S100_hum_2_Married.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S100_hum_2_Marrie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S100</td>\n",
       "      <td>whistle</td>\n",
       "      <td>2</td>\n",
       "      <td>Friend</td>\n",
       "      <td>S100_whistle_2_Friend.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S100_whistle_2_Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S100</td>\n",
       "      <td>whistle</td>\n",
       "      <td>2</td>\n",
       "      <td>Happy</td>\n",
       "      <td>S100_whistle_2_Happy.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S100_whistle_2_Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S100</td>\n",
       "      <td>whistle</td>\n",
       "      <td>2</td>\n",
       "      <td>RememberMe</td>\n",
       "      <td>S100_whistle_2_RememberMe.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S100_whistle_2_Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S101</td>\n",
       "      <td>hum</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>S101_hum_1_Married.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S101_hum_1_Marrie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id recording_type interpretation_number        song  \\\n",
       "0           S100            hum                     2     Married   \n",
       "1           S100        whistle                     2      Friend   \n",
       "2           S100        whistle                     2       Happy   \n",
       "3           S100        whistle                     2  RememberMe   \n",
       "4           S101            hum                     1     Married   \n",
       "\n",
       "                        filename  \\\n",
       "0         S100_hum_2_Married.wav   \n",
       "1      S100_whistle_2_Friend.wav   \n",
       "2       S100_whistle_2_Happy.wav   \n",
       "3  S100_whistle_2_RememberMe.wav   \n",
       "4         S101_hum_1_Married.wav   \n",
       "\n",
       "                                            filepath  \n",
       "0  ../data/MLEndHWII_sample_800\\S100_hum_2_Marrie...  \n",
       "1  ../data/MLEndHWII_sample_800\\S100_whistle_2_Fr...  \n",
       "2  ../data/MLEndHWII_sample_800\\S100_whistle_2_Ha...  \n",
       "3  ../data/MLEndHWII_sample_800\\S100_whistle_2_Re...  \n",
       "4  ../data/MLEndHWII_sample_800\\S101_hum_1_Marrie...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_800 = \"../data/MLEndHWII_sample_800\"\n",
    "df_800 = build_index(path_800)\n",
    "print(\"Dataset B:\", len(df_800), \"samples\")\n",
    "df_800.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ed337-8aed-499a-a726-b67c867e45c4",
   "metadata": {},
   "source": [
    "## 5.3 Training Dataset & 5.4 Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac0d536-9784-4bc4-bed9-54904d5103fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Size: 640\n",
      "Validation Dataset Size: 160\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_800, test_size = 0.20, random_state = 42, stratify = df_800[\"song\"])  # preserves class distribution\n",
    "\n",
    "print(\"Training Dataset Size:\", len(df_train))\n",
    "print(\"Validation Dataset Size:\", len(df_val))\n",
    "\n",
    "# Reset indices for convenience\n",
    "df_train = df_train.reset_index(drop = True)\n",
    "df_val = df_val.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a803d9e6-207a-4d2e-b79b-6c2d22d45ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>recording_type</th>\n",
       "      <th>interpretation_number</th>\n",
       "      <th>song</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S108</td>\n",
       "      <td>whistle</td>\n",
       "      <td>1</td>\n",
       "      <td>Feeling</td>\n",
       "      <td>S108_whistle_1_Feeling.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S108_whistle_1_Fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S48</td>\n",
       "      <td>hum</td>\n",
       "      <td>1</td>\n",
       "      <td>RememberMe</td>\n",
       "      <td>S48_hum_1_RememberMe.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S48_hum_1_Remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S69</td>\n",
       "      <td>whistle</td>\n",
       "      <td>2</td>\n",
       "      <td>Necessities</td>\n",
       "      <td>S69_whistle_2_Necessities.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S69_whistle_2_Nec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S35</td>\n",
       "      <td>hum</td>\n",
       "      <td>3</td>\n",
       "      <td>Feeling</td>\n",
       "      <td>S35_hum_3_Feeling.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S35_hum_3_Feeling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S89</td>\n",
       "      <td>whistle</td>\n",
       "      <td>2</td>\n",
       "      <td>Married</td>\n",
       "      <td>S89_whistle_2_Married.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S89_whistle_2_Mar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id recording_type interpretation_number         song  \\\n",
       "0           S108        whistle                     1      Feeling   \n",
       "1            S48            hum                     1   RememberMe   \n",
       "2            S69        whistle                     2  Necessities   \n",
       "3            S35            hum                     3      Feeling   \n",
       "4            S89        whistle                     2      Married   \n",
       "\n",
       "                        filename  \\\n",
       "0     S108_whistle_1_Feeling.wav   \n",
       "1       S48_hum_1_RememberMe.wav   \n",
       "2  S69_whistle_2_Necessities.wav   \n",
       "3          S35_hum_3_Feeling.wav   \n",
       "4      S89_whistle_2_Married.wav   \n",
       "\n",
       "                                            filepath  \n",
       "0  ../data/MLEndHWII_sample_800\\S108_whistle_1_Fe...  \n",
       "1  ../data/MLEndHWII_sample_800\\S48_hum_1_Remembe...  \n",
       "2  ../data/MLEndHWII_sample_800\\S69_whistle_2_Nec...  \n",
       "3  ../data/MLEndHWII_sample_800\\S35_hum_3_Feeling...  \n",
       "4  ../data/MLEndHWII_sample_800\\S89_whistle_2_Mar...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0ea0e8-a849-40a7-91a6-8db474022239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>recording_type</th>\n",
       "      <th>interpretation_number</th>\n",
       "      <th>song</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S29</td>\n",
       "      <td>hum</td>\n",
       "      <td>3</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>S29_hum_3_NewYork.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S29_hum_3_NewYork...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S82</td>\n",
       "      <td>hum</td>\n",
       "      <td>1</td>\n",
       "      <td>Happy</td>\n",
       "      <td>S82_hum_1_Happy.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S82_hum_1_Happy.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S19</td>\n",
       "      <td>whistle</td>\n",
       "      <td>1</td>\n",
       "      <td>Happy</td>\n",
       "      <td>S19_whistle_1_Happy.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S19_whistle_1_Hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S173</td>\n",
       "      <td>whistle</td>\n",
       "      <td>1</td>\n",
       "      <td>RememberMe</td>\n",
       "      <td>S173_whistle_1_RememberMe.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S173_whistle_1_Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S70</td>\n",
       "      <td>hum</td>\n",
       "      <td>3</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>S70_hum_3_NewYork.wav</td>\n",
       "      <td>../data/MLEndHWII_sample_800\\S70_hum_3_NewYork...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id recording_type interpretation_number        song  \\\n",
       "0            S29            hum                     3     NewYork   \n",
       "1            S82            hum                     1       Happy   \n",
       "2            S19        whistle                     1       Happy   \n",
       "3           S173        whistle                     1  RememberMe   \n",
       "4            S70            hum                     3     NewYork   \n",
       "\n",
       "                        filename  \\\n",
       "0          S29_hum_3_NewYork.wav   \n",
       "1            S82_hum_1_Happy.wav   \n",
       "2        S19_whistle_1_Happy.wav   \n",
       "3  S173_whistle_1_RememberMe.wav   \n",
       "4          S70_hum_3_NewYork.wav   \n",
       "\n",
       "                                            filepath  \n",
       "0  ../data/MLEndHWII_sample_800\\S29_hum_3_NewYork...  \n",
       "1   ../data/MLEndHWII_sample_800\\S82_hum_1_Happy.wav  \n",
       "2  ../data/MLEndHWII_sample_800\\S19_whistle_1_Hap...  \n",
       "3  ../data/MLEndHWII_sample_800\\S173_whistle_1_Re...  \n",
       "4  ../data/MLEndHWII_sample_800\\S70_hum_3_NewYork...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf9c78-1484-468c-a1be-c06d7b327bd0",
   "metadata": {},
   "source": [
    "## Song Distribution Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc55a5ce-e214-4503-a1e4-bb7a705fc4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>song</th>\n",
       "      <th>Feeling</th>\n",
       "      <th>Friend</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Married</th>\n",
       "      <th>Necessities</th>\n",
       "      <th>NewYork</th>\n",
       "      <th>RememberMe</th>\n",
       "      <th>TryEverything</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dataset A</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset B</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training Dataset</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Dataset</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "song                Feeling  Friend  Happy  Married  Necessities  NewYork  \\\n",
       "Dataset A                50      50     50       50           50       50   \n",
       "Dataset B               100     100    100      100          100      100   \n",
       "Training Dataset         80      80     80       80           80       80   \n",
       "Validation Dataset       20      20     20       20           20       20   \n",
       "\n",
       "song                RememberMe  TryEverything  \n",
       "Dataset A                   50             50  \n",
       "Dataset B                  100            100  \n",
       "Training Dataset            80             80  \n",
       "Validation Dataset          20             20  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = { \"Dataset A\" : df_400,\n",
    "             \"Dataset B\" : df_800,\n",
    "             \"Training Dataset\" : df_train,\n",
    "             \"Validation Dataset\" : df_val            \n",
    "            }\n",
    "\n",
    "song_tables = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    song_tables[name] = df[\"song\"].value_counts()\n",
    "\n",
    "song_dist_table = pd.DataFrame(song_tables).fillna(0).astype(int).T\n",
    "song_dist_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7427b-6860-433a-b07d-b9543495c852",
   "metadata": {},
   "source": [
    "All four datasets show a perfectly balanced distribution across the eight songs. Each song has the same number of samples within each dataset (50 in Dataset A, 100 in Dataset B, 80 in Training, and 20 in Validation). This uniformity prevents class imbalance and ensures fair model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f4cc9-10d0-47cc-a77d-e39b04bc0b7a",
   "metadata": {},
   "source": [
    "## Recording Type Distribution Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428a8716-8e2d-4f0b-9137-2f0420a23ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>recording_type</th>\n",
       "      <th>hum</th>\n",
       "      <th>whistle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dataset A</th>\n",
       "      <td>201</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset B</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training Dataset</th>\n",
       "      <td>317</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Dataset</th>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "recording_type      hum  whistle\n",
       "Dataset A           201      199\n",
       "Dataset B           400      400\n",
       "Training Dataset    317      323\n",
       "Validation Dataset   83       77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_tables = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    rec_tables[name] = df[\"recording_type\"].value_counts()\n",
    "\n",
    "recording_dist_table = pd.DataFrame(rec_tables).fillna(0).astype(int).T\n",
    "recording_dist_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e1765-2b2e-4250-ba5f-3a4a00e619d8",
   "metadata": {},
   "source": [
    "The datasets show an almost balanced split between hum and whistle recordings. While minor differences exist, the overall distribution remains well balanced and should not introduce significant class bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519531c7-c4c4-49c6-9516-512a37431f90",
   "metadata": {},
   "source": [
    "## Participant ID Distribution Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547dde65-1a61-4b8a-aae4-38a5f7c1cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>participant_id</th>\n",
       "      <th>S1</th>\n",
       "      <th>S10</th>\n",
       "      <th>S100</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>S104</th>\n",
       "      <th>S105</th>\n",
       "      <th>S106</th>\n",
       "      <th>S107</th>\n",
       "      <th>...</th>\n",
       "      <th>S90</th>\n",
       "      <th>S91</th>\n",
       "      <th>S92</th>\n",
       "      <th>S93</th>\n",
       "      <th>S94</th>\n",
       "      <th>S95</th>\n",
       "      <th>S96</th>\n",
       "      <th>S97</th>\n",
       "      <th>S98</th>\n",
       "      <th>S99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dataset A</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset B</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training Dataset</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Dataset</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "participant_id      S1  S10  S100  S101  S102  S103  S104  S105  S106  S107  \\\n",
       "Dataset A            3    1     3     2     0     2     3     2     2     1   \n",
       "Dataset B            5    5     4     4     4     4     4     4     5     4   \n",
       "Training Dataset     4    4     3     3     3     4     2     1     4     3   \n",
       "Validation Dataset   1    1     1     1     1     0     2     3     1     1   \n",
       "\n",
       "participant_id      ...  S90  S91  S92  S93  S94  S95  S96  S97  S98  S99  \n",
       "Dataset A           ...    1    3    1    2    3    1    3    5    2    4  \n",
       "Dataset B           ...    4    5    4    4    5    4    4    5    4    4  \n",
       "Training Dataset    ...    3    3    2    3    4    3    4    5    4    3  \n",
       "Validation Dataset  ...    1    2    2    1    1    1    0    0    0    1  \n",
       "\n",
       "[4 rows x 187 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_tables = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    participant_tables[name] = df[\"participant_id\"].value_counts()\n",
    "\n",
    "participant_dist_table = pd.DataFrame(participant_tables).fillna(0).astype(int).T\n",
    "participant_dist_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba9dc9-1590-491d-bc91-58ce52a810dd",
   "metadata": {},
   "source": [
    "Participant contributions are uneven across the datasets. While Dataset B shows relatively consistent counts per participant, Dataset A and the training/validation splits show noticeable imbalance. This uneven representation may introduce bias during model training, where the model could overfit to participants with more samples and underperform on underrepresented ones. Additionally, participants with zero or very few recordings limit the model‚Äôs ability to generalize. These imbalances may need to be addressed through methods such as weighted sampling or data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8904d6-e4a8-41b9-9cf9-7b567265422a",
   "metadata": {},
   "source": [
    "# 6 Experiments and Results\n",
    "\n",
    "This section presents the experiments conducted using the three proposed models: Logistic Regression, Random Forest, and Convolutional Neural Networks (CNNs). Each model follows a defined preprocessing and feature-extraction pipeline, and results are analysed in the context of the dataset characteristics established in Section 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7bf7-32c8-4404-b0da-b6117ff4a884",
   "metadata": {},
   "source": [
    "## 6.1 Preprocessing Pipelines (Applied to All Models)\n",
    "\n",
    "Before feature extraction, all audio files across the four datasets underwent consistent preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c94e10-a8f5-4343-8165-2ea4d57f617f",
   "metadata": {},
   "source": [
    "**1. Amplitude Normalisation:** Ensured that recordings with different loudness levels were mapped to a common amplitude scale. The following function normalises amplitude to range [-1, 1]. It prevents loud recordings from dominating learned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f04215b-04db-458a-8d28-bf07e64c8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(y):\n",
    "   \n",
    "    if np.max(np.abs(y)) == 0:\n",
    "        return y\n",
    "    return y / np.max(np.abs(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc32840-6ae9-4047-a51e-9ccabaa42e42",
   "metadata": {},
   "source": [
    "**2. Resampling to a Standard Sample Rate (e.g., 16 kHz):** This eliminated variability due to the original recording devices. This function resamples the waveform to the target sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dae8dc8-9679-403b-bacf-91d61056b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SR = 16000 \n",
    "\n",
    "def resample_audio(y, orig_sr, target_sr = TARGET_SR):\n",
    "   \n",
    "    if orig_sr == target_sr:\n",
    "        return y\n",
    "        \n",
    "    return librosa.resample(y, orig_sr = orig_sr, target_sr = target_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a40f9c-d20b-4355-9cf7-2b96af6e7a3c",
   "metadata": {},
   "source": [
    "**3. Padding/Truncation to Fixed Duration (10 seconds):** Guaranteed uniform input size for all models. This functions ensures waveform has a fixed number of samples. It truncate if it is too long, otherwise it will pad with zeros if it is too short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d42a18-ede7-4a6c-bbf4-c2a996bb7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DURATION = 10.0   # seconds\n",
    "TARGET_SAMPLES = int(TARGET_SR * TARGET_DURATION)\n",
    "\n",
    "def pad_or_truncate(y, target_length = TARGET_SAMPLES):\n",
    "    \n",
    "    if len(y) > target_length:\n",
    "        return y[:target_length]\n",
    "    else:\n",
    "        return np.pad(y, (0, target_length - len(y)), mode = \"constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e768597-e709-4ce3-bf39-f8b48ea580df",
   "metadata": {},
   "source": [
    "**4. Data Augmentation (Training Set Only):**  This expanded the training distribution, compensating for participant imbalance and increasing robustness. We do it only for training dataset since augmentation simulates variability that improves generalisation, and validation sets must reflect real conditions, not artificially modified audio.\n",
    "\n",
    "* `¬± pitch shifting:` Slightly raises or lowers the pitch to simulate natural variations in how different people hum or whistle the same melody.\n",
    "* `Time-stretching:` Speeds up or slows down the audio without changing pitch, modelling differences in tempo across performances.\n",
    "* `Light background noise:` Adds a small amount of noise to make the model more robust to real recording environments and microphone imperfections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8d5e61-313a-437b-bce8-6b7cf1b83481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Process\n",
    "\n",
    "#  pitch shifting\n",
    "def augment_pitch_shift(y, sr, max_steps = 2):\n",
    "    steps = random.uniform(-max_steps, max_steps)\n",
    "    return librosa.effects.pitch_shift(y, sr = sr, n_steps = steps)\n",
    "\n",
    "#  time stretching\n",
    "def augment_time_stretch(y, max_rate_change=0.15):\n",
    "    rate = 1.0 + random.uniform(-max_rate_change, max_rate_change)\n",
    "    y_stretched = librosa.effects.time_stretch(y.astype(float), rate=rate)\n",
    "    return pad_or_truncate(y_stretched)\n",
    "\n",
    "#  noise injection \n",
    "def augment_noise(y, noise_factor = 0.005):\n",
    "    noise = np.random.randn(len(y))\n",
    "    return y + noise_factor * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d39596-59b4-4951-99d4-425fe6f7ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Master Function\n",
    "\n",
    "def apply_augmentation(y, sr):\n",
    "    augmentations = [\n",
    "        lambda x: augment_pitch_shift(x, sr),\n",
    "        lambda x: augment_time_stretch(x),\n",
    "        lambda x: augment_noise(x)\n",
    "    ]\n",
    "\n",
    "    # randomly choose how many augmentations to apply (0, 1, or 2)\n",
    "    num_to_apply = random.choice([0,1,2])\n",
    "    selected = random.sample(augmentations, num_to_apply)\n",
    "\n",
    "    y_aug = y.copy()\n",
    "    for aug in selected:\n",
    "        y_aug = aug(y_aug)\n",
    "\n",
    "    return y_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e798bca-0d51-4aad-92c4-0a827532dbcf",
   "metadata": {},
   "source": [
    "This is the overall function that performs the final preprocessing for the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a65b396-b699-449d-b509-764335da91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Preprocessing Function\n",
    "\n",
    "def preprocess_audio(filepath, apply_aug = False):\n",
    "\n",
    "    # Load\n",
    "    y, sr = librosa.load(filepath, sr = None)\n",
    "\n",
    "    # Preprocessing\n",
    "    y = normalize_audio(y)\n",
    "    y = resample_audio(y, sr, TARGET_SR)\n",
    "    y = pad_or_truncate(y)\n",
    "\n",
    "    # Augmentation (training set only)\n",
    "    if apply_aug:\n",
    "        y = apply_augmentation(y, TARGET_SR)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5966037-8010-4f80-85e4-0bc65b700b87",
   "metadata": {},
   "source": [
    "## 6.2 Feature Extraction\n",
    "\n",
    "After preprocessing, audio samples are transformed into numerical feature representations suitable for machine-learning models. Two feature types are used:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a5352-d114-4a23-b9a7-53ad104e274a",
   "metadata": {},
   "source": [
    "### 6.2.1 MFCC Features (For Logistic Regression & Random Forest)\n",
    "\n",
    "MFCCs compress the spectral envelope of the humming/whistling audio into a compact, perceptually meaningful representation.\n",
    "We extract 20‚Äì40 coefficients per frame and flatten them into a 1D vector, which is ideal for classical ML models that expect fixed-length feature inputs.\n",
    "\n",
    "This function extracts MFCCs, and the matrix is flattened into a fixed-length vector, making it compatible with logistic regression and random forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "523ddd61-e464-45ff-9392-8361bc1c3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(audio, sr, n_mfcc=30):\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y = audio,\n",
    "        sr = sr,\n",
    "        n_mfcc = n_mfcc,\n",
    "        n_fft = 1024,\n",
    "        hop_length = 512)\n",
    "\n",
    "    # Flatten (num_coeffs √ó num_frames) ‚Üí 1D vector\n",
    "    return mfcc.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb0a81e-ef35-4b01-83b8-dd9be357179f",
   "metadata": {},
   "source": [
    "### 6.2.2 Log-Mel Spectrograms (For CNN Model)\n",
    "\n",
    "Log-Mel spectrograms retain detailed time‚Äìfrequency structure.\n",
    "They act like 2D images (frequency √ó time), making them suitable for convolutional neural networks that learn spatial patterns such as pitch contours and harmonic shapes. \n",
    "\n",
    "This function extracts a 2D log-mel spectrogram (frequency x time) and it returns a shape: (n_mels, time_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20a2025d-2b76-4902-bcbb-3927f8b60e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_logmel(audio, sr, n_mels = 64):\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y = audio,\n",
    "        sr = sr,\n",
    "        n_fft = 1024,\n",
    "        hop_length = 512,\n",
    "        n_mels = n_mels,\n",
    "        fmin = 40,\n",
    "        fmax = sr//2)\n",
    "\n",
    "    # Convert to log scale\n",
    "    log_mel = librosa.power_to_db(mel, ref = np.max)\n",
    "\n",
    "    return log_mel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c32186-f1d9-4e8b-8210-e9b12e5f95bf",
   "metadata": {},
   "source": [
    "### 6.2.3 Unified Feature Extraction Function\n",
    "\n",
    "The following function is used to provide a single, consistent interface for extracting MFCC or log-mel features, reducing code duplication and making it easy to switch feature types across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c32f00b-8295-4660-af6d-718ec8c52209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio, sr, mode = \"mfcc\"):\n",
    "    if mode == \"mfcc\":\n",
    "        return extract_mfcc(audio, sr)\n",
    "    elif mode == \"logmel\":\n",
    "        return extract_logmel(audio, sr)\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'mfcc' or 'logmel'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3609a-fe84-4128-8fbc-c06b266fed74",
   "metadata": {},
   "source": [
    "### 6.2.4 Dataset Feature Extraction Pipeline\n",
    "\n",
    "To apply the above feature extractors to entire datasets, we implement a helper function that iterates through the dataframe, loads each audio file, applies preprocessing, and extracts either MFCC or Log-Mel features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f4a4571-a47d-4459-a6f0-d456ef1951ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_extract_features(df, feature_type=\"mfcc\", apply_aug=False):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        filepath = row[\"filepath\"]\n",
    "        label = row[\"song\"]\n",
    "\n",
    "        # 1. Preprocess (loads audio internally)\n",
    "        y = preprocess_audio(filepath, apply_aug = apply_aug)\n",
    "\n",
    "        # 2. Extract features\n",
    "        feat = extract_features(y, TARGET_SR, mode = feature_type)\n",
    "\n",
    "        features.append(feat)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(features, dtype=\"object\"), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363dcac-453a-4957-a150-8928f398f61a",
   "metadata": {},
   "source": [
    "## 6.3 ML Models\n",
    "\n",
    "The experimental workflow was designed to ensure a rigorous and fair comparison between classical machine-learning models and the Convolutional Neural Network (CNN). The procedure consists of three stages:\n",
    "\n",
    "1) Feature Extraction\n",
    "2) Training Stage\n",
    "3) Validation Stage\n",
    "4) Testing Stage: on two independent datasets\n",
    "  \n",
    "This structure enables controlled model selection while also assessing generalisation across datasets with differing sample sizes and participant distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9532c-f586-4449-90cc-893d5acd4c8e",
   "metadata": {},
   "source": [
    "## 6.3.1 Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3adfb6-e4cd-40ca-98f8-dbe06c2639c2",
   "metadata": {},
   "source": [
    "### 1. Feature Extraction (MFCCs)\n",
    "\n",
    "MFCCs produce a 2D matrix (coefficients √ó frames).  \n",
    "For classical models such as Logistic Regression, these are **flattened into a single vector**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e250bb11-0b0a-4152-9934-b9620c19de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set (with augmentation)\n",
    "X_train_mfcc, y_train = process_and_extract_features(df_train, feature_type = \"mfcc\", apply_aug = True)\n",
    "\n",
    "# Validation Set\n",
    "X_val_mfcc, y_val = process_and_extract_features(df_val, feature_type = \"mfcc\", apply_aug = False)\n",
    "\n",
    "# Test A (400 samples)\n",
    "X_testA_mfcc, y_testA = process_and_extract_features(df_400, feature_type = \"mfcc\", apply_aug = False)\n",
    "\n",
    "# Test Set B (800 samples)\n",
    "X_testB_mfcc, y_testB = process_and_extract_features(df_800, feature_type = \"mfcc\", apply_aug = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b623f87f-fa7a-4fd6-8113-ee5b49a3bbc9",
   "metadata": {},
   "source": [
    "### 2. Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28809085-7e9c-435c-b114-9734d03bf93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oscar\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialise the model\n",
    "logreg = LogisticRegression(\n",
    "    max_iter = 1000,\n",
    "    solver = \"lbfgs\",\n",
    "    multi_class = \"multinomial\"\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "logreg.fit(list(X_train_mfcc), y_train)\n",
    "\n",
    "print(\"Logistic Regression training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd251a-ab93-421e-a5e6-3c0ed6656aed",
   "metadata": {},
   "source": [
    "### 3. Validation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "053b135f-f417-4c6e-93fe-5fc00cff0293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3375\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = logreg.predict(list(X_val_mfcc))\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", round(val_acc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42094617-15e1-42d1-9a7d-a0931a709c4b",
   "metadata": {},
   "source": [
    "### 4. Testing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74aa1550-8811-44c1-bcab-2e7d26620f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on Dataset A (400): 0.7075\n",
      "Test Accuracy on Dataset B (800): 0.7125\n"
     ]
    }
   ],
   "source": [
    "# Test on Dataset A (400 samples) \n",
    "y_testA_pred = logreg.predict(list(X_testA_mfcc))\n",
    "acc_A = accuracy_score(y_testA, y_testA_pred)\n",
    "\n",
    "#  Test on Dataset B (800 samples) \n",
    "y_testB_pred = logreg.predict(list(X_testB_mfcc))\n",
    "acc_B = accuracy_score(y_testB, y_testB_pred)\n",
    "\n",
    "print(\"Test Accuracy on Dataset A (400):\", round(acc_A, 4))\n",
    "print(\"Test Accuracy on Dataset B (800):\", round(acc_B, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ecdd6-15ce-4e25-b561-0e15a0379513",
   "metadata": {},
   "source": [
    "### 5. Results Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27716e-b278-456b-ae98-4c34db6c79de",
   "metadata": {},
   "source": [
    "**Overall performance**\n",
    "\n",
    "The Logistic Regression baseline achieved:\n",
    "\n",
    "* 33.75% accuracy on the validation set\n",
    "* 70.75% accuracy on Test Set A (400 samples)\n",
    "* 71.25% accuracy on Test Set B (800 samples)\n",
    "\n",
    "These results show that the model performs poorly on validation, but much better on the external test sets, suggesting that:\n",
    "\n",
    "1. The validation set may be more challenging, either because:\n",
    "\n",
    "* It contains more ambiguous examples\n",
    "* The distribution differs slightly\n",
    "* The model overfits some characteristics of the training set.\n",
    "\n",
    "2. Logistic Regression benefits from more data, as evidenced by:\n",
    "\n",
    "* Stable performance between Test A and Test B\n",
    "* Both external datasets showing significantly higher accuracy than validation\n",
    "\n",
    "\n",
    "**Reasons why validation accuracy is low**\n",
    "\n",
    "* Logistic Regression is a linear classifier: MFCC-based classification of musical melodies is highly nonlinear, and logistic regression struggles to model this complexity.\n",
    "* MFCCs may not capture enough melodic detail\n",
    "MFCCs are designed for timbre, not melody, so distinguishing many similar songs becomes difficult.\n",
    "* Class imbalance: Some songs may have fewer training examples, hurting the model‚Äôs generalization.\n",
    "* Simple augmentation: Although augmentation helps, a linear model cannot fully exploit the variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ab732-83bb-4a7a-a71e-ab296d0b40dd",
   "metadata": {},
   "source": [
    "## 6.3.2 Random Forest Model\n",
    "\n",
    "Random Forest is a classical ensemble learning algorithm that combines multiple decision trees.\n",
    "Unlike Logistic Regression (linear model), Random Forest can model non-linear relationships and feature interactions, making it a stronger baseline for MFCC features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d1dc8d-8d09-49d1-a865-f9181fefd85c",
   "metadata": {},
   "source": [
    "### 1. Feature Extraction (MFCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a302fac0-ac09-4dee-9f6e-2c4ee47a68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set (with augmentation)\n",
    "X_train_rf, y_train_rf = process_and_extract_features(df_train, feature_type=\"mfcc\", apply_aug=True)\n",
    "\n",
    "# Validation Set\n",
    "X_val_rf, y_val_rf = process_and_extract_features(df_val, feature_type=\"mfcc\", apply_aug=False)\n",
    "\n",
    "# Test A (400 samples)\n",
    "X_testA_rf, y_testA_rf = process_and_extract_features(df_400, feature_type=\"mfcc\", apply_aug=False)\n",
    "\n",
    "# Test B (800 samples)\n",
    "X_testB_rf, y_testB_rf = process_and_extract_features(df_800, feature_type=\"mfcc\", apply_aug=False)\n",
    "\n",
    "# Convert list of variable-sized MFCC arrays to fixed vectors\n",
    "X_train_rf = np.vstack(X_train_rf)\n",
    "X_val_rf   = np.vstack(X_val_rf)\n",
    "X_testA_rf = np.vstack(X_testA_rf)\n",
    "X_testB_rf = np.vstack(X_testB_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e0d5d-a727-4cf1-a789-c88074962137",
   "metadata": {},
   "source": [
    "### 2. Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6422bdb-b217-47ad-85f5-315d2c9cbba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7acaed-14f8-4acf-ab79-ca177ae68a6c",
   "metadata": {},
   "source": [
    "### 3. Validation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd71ce09-b7ed-409b-a175-d10e961fd0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.2562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "val_pred = rf_model.predict(X_val_rf)\n",
    "val_acc = accuracy_score(y_val_rf, val_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", round(val_acc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2a815-54da-49bd-998c-28c0f8a86c48",
   "metadata": {},
   "source": [
    "### 4. Testing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "727f6efc-6811-4db2-b8e9-f8136c7376ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy A (400-sample): 0.69\n",
      "Test Accuracy B (800-sample): 0.6825\n"
     ]
    }
   ],
   "source": [
    "testA_pred = rf_model.predict(X_testA_rf)\n",
    "testB_pred = rf_model.predict(X_testB_rf)\n",
    "\n",
    "test_acc_A = accuracy_score(y_testA_rf, testA_pred)\n",
    "test_acc_B = accuracy_score(y_testB_rf, testB_pred)\n",
    "\n",
    "print(\"Test Accuracy A (400-sample):\", round(test_acc_A, 4))\n",
    "print(\"Test Accuracy B (800-sample):\", round(test_acc_B, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c0441-1e82-49a1-999e-d6f70666deb1",
   "metadata": {},
   "source": [
    "### 5. Secondary Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b84cce-6bfd-447e-bb16-9c4c6906e6ce",
   "metadata": {},
   "source": [
    "#### 5. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4bca6b5-6aa7-4624-a40a-8850af11861b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val_rf, val_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
    "plt.title(\"Random Forest ‚Äì Confusion Matrix (Validation)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc99c8f-6c27-4137-a66e-505681fa348d",
   "metadata": {},
   "source": [
    "#### 5.2 Classification Report\n",
    "\n",
    "This gives:\n",
    "\n",
    "* Per-class Precision\n",
    "* Per-class Recall\n",
    "* Per-class F1\n",
    "* Macro F1\n",
    "* Weighted F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6fd695a-3e68-4b48-bd15-7ad46b13116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Feeling       0.28      0.25      0.26        20\n",
      "       Friend       0.32      0.45      0.38        20\n",
      "        Happy       0.12      0.15      0.13        20\n",
      "      Married       0.22      0.10      0.14        20\n",
      "  Necessities       0.40      0.30      0.34        20\n",
      "      NewYork       0.20      0.20      0.20        20\n",
      "   RememberMe       0.19      0.25      0.22        20\n",
      "TryEverything       0.39      0.35      0.37        20\n",
      "\n",
      "     accuracy                           0.26       160\n",
      "    macro avg       0.26      0.26      0.25       160\n",
      " weighted avg       0.26      0.26      0.25       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_rf, val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726ea3c-3754-4f19-82b8-d1976b400772",
   "metadata": {},
   "source": [
    "#### 5.3 Top-k Accuracy (k = 3 and k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef49538c-6482-4887-a2c5-91827c35b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy: 0.6\n",
      "Top-5 Accuracy: 0.7875\n"
     ]
    }
   ],
   "source": [
    "probs_val = rf_model.predict_proba(X_val_rf)\n",
    "classes = rf_model.classes_\n",
    "\n",
    "def top_k_accuracy(y_true, probs, labels, k):\n",
    "    correct = 0\n",
    "    for i in range(len(y_true)):\n",
    "        top_k_idx = np.argsort(probs[i])[::-1][:k]\n",
    "        top_k_labels = labels[top_k_idx]\n",
    "        if y_true[i] in top_k_labels:\n",
    "            correct += 1\n",
    "    return correct / len(y_true)\n",
    "\n",
    "top3 = top_k_accuracy(y_val_rf, probs_val, classes, k=3)\n",
    "top5 = top_k_accuracy(y_val_rf, probs_val, classes, k=5)\n",
    "\n",
    "print(\"Top-3 Accuracy:\", round(top3, 4))\n",
    "print(\"Top-5 Accuracy:\", round(top5, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c16db4-826c-4c7f-921b-126ed631d495",
   "metadata": {},
   "source": [
    "### 6. Results Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ea343-d724-4ff1-b0c8-396b775050e3",
   "metadata": {},
   "source": [
    "**Overall Performance**\n",
    "\n",
    "The Random Forest shows a similar pattern to the Logistic Regression model:\n",
    "\n",
    "* Validation accuracy is low (0.25)\n",
    "* Test accuracy on the smaller 400-sample dataset is high (0.6)\n",
    "* Test accuracy on the larger 800-sample dataset is also high (0.78)\n",
    "\n",
    "This behaviour indicates that the model struggles during validation on the training domain, but generalises surprisingly well to external datasets.\n",
    "\n",
    "Combined with the confusion-matrix metrics, this suggests that Random Forest is not learning a deeply discriminative representation during training, but still captures broad MFCC-based acoustic patterns, which transfer well across datasets.\n",
    "\n",
    "\n",
    "**Reasons Why Validation Accuracy Is Low**\n",
    "\n",
    "1. MFCC features cause information loss: MFCCs compress the audio heavily, removing pitch contour and fine-grained humming structure.\n",
    "Random Forests cannot recover the lost harmonic/temporal relationships, leading to weaker in-domain learning.\n",
    "\n",
    "2. Random Forests struggle with very high-dimensional flattened MFCCs: Flattened MFCC matrices produce feature vectors with thousands of coefficients.\n",
    "Tree-based models perform poorly when:\n",
    "\n",
    "* The number of features ‚â´ number of samples\n",
    "* Features are continuous and noisy\n",
    "* Many features are highly correlated (MFCC frames are almost identical over time)\n",
    "\n",
    "    This leads to unstable splits and lower validation performance.\n",
    "\n",
    "\n",
    "3. Validation uses augmented-free audios while training uses augmented audio\n",
    "\n",
    "    This creates:\n",
    "\n",
    "* A domain gap between the augmented training distribution and the clean validation distribution.\n",
    "* Random Forests cannot generalise well across distribution shifts, unlike neural networks.\n",
    "\n",
    "\n",
    "**Secondary Metrics Intepretration**\n",
    "\n",
    "1. **Precision and recall are inconsistent across classes**\n",
    "\n",
    "* Friend: reasonable recall (0.45) = The model predicts this class more frequently\n",
    "* Married: low recall (0.10) = The model fails to recognise this song\n",
    "* Happy: both precision (0.12) and recall (0.15) are low = difficult class\n",
    "* NewYork: low precision (0.20) and low recall (0.20) = not very easy to distinct the melody\n",
    "\n",
    "This inequality suggests:\n",
    "\n",
    "* Some songs have more distinctive MFCC patterns\n",
    "* Others might have overlapping frequency envelopes when hummed\n",
    "* The model tends to confuse songs with similar spectral shapes\n",
    "* Songs with subtle or smoother humming shape (e.g., Married, Happy) are often missed.\n",
    "\n",
    "\n",
    "2. **Macro F1 = 0.25**\n",
    "\n",
    "Macro treats all classes equally. Low macro F1 means:\n",
    "\n",
    "* Underperformance is not isolated to a couple of songs\n",
    "* The model struggles globally, not just with rare classes\n",
    "\n",
    "3. **Weighted F1 = 0.25**\n",
    "\n",
    "    Since each class has the same number of samples, weighted F1 does not distort the view. Thus, the low F1 truly reflects real class-level difficulties.\n",
    "\n",
    "The Random Forest model captures broad MFCC patterns well enough to generalise to external datasets but fails to learn robust class-specific representations, leading to low validation performance and uniformly weak precision/recall across classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b704c355-c863-47a4-a987-7d99f0ee6759",
   "metadata": {},
   "source": [
    "## 6.3.3 Convoluted Neural Networks Model\n",
    "\n",
    "This model uses **log-mel spectrograms** as 2D inputs to a convolutional neural network.  \n",
    "Spectrograms preserve time‚Äìfrequency structure, allowing the CNN to learn local patterns (pitch contours, harmonics) that are important for distinguishing hummed melodies.\n",
    "\n",
    "We fix the spectrogram shape to **(64 mel bands √ó 312 time frames)** (one channel) so the network receives uniform inputs.  \n",
    "Training uses early stopping on validation loss to reduce overfitting and data augmentation is applied only to the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dbfb1a-1187-4ae3-a08c-3467930f5d05",
   "metadata": {},
   "source": [
    "### 1. Data Preparation: Pad/Crop Spectrograms & Prepare Dataset\n",
    "\n",
    "To train a convolutional neural network, all inputs must share a consistent shape. However, log-mel spectrograms derived from different audio files may vary in time duration due to small differences in recording length or preprocessing. This subsection standardizes all spectrograms by padding or cropping them to a fixed number of time frames, ensuring that each sample has identical dimensions. This step enables efficient batching, GPU processing, and stable model convergence. Additionally, data augmentation is applied during training to improve generalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f6151d8-2a10-4fa1-8f8d-e68c6cd6f536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train_mel: (640, 64, 312, 1)\n",
      "X_val_mel: (160, 64, 312, 1)\n",
      "X_testA_mel: (400, 64, 312, 1)\n",
      "X_testB_mel: (800, 64, 312, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Target spectrogram size\n",
    "N_MELS = 64\n",
    "TARGET_FRAMES = 312\n",
    "\n",
    "def pad_or_crop_spectrogram(spec, target_frames=TARGET_FRAMES):\n",
    "    n_mels, frames = spec.shape\n",
    "    if frames == target_frames:\n",
    "        return spec\n",
    "    if frames > target_frames:\n",
    "        return spec[:, :target_frames]\n",
    "    pad_width = target_frames - frames\n",
    "    return np.pad(spec, ((0,0),(0,pad_width)), mode='constant', constant_values=(spec.min(),))\n",
    "\n",
    "def prepare_logmel_dataset(df, apply_aug=False):\n",
    "    specs = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        filepath = row[\"filepath\"]\n",
    "        label = row[\"song\"]\n",
    "        y = preprocess_audio(filepath, apply_aug=apply_aug)\n",
    "        spec = extract_logmel(y, TARGET_SR, n_mels=N_MELS)\n",
    "        spec_fixed = pad_or_crop_spectrogram(spec, TARGET_FRAMES)\n",
    "        specs.append(spec_fixed.astype(np.float32))\n",
    "        labels.append(label)\n",
    "    X = np.stack(specs)[..., np.newaxis]  # add channel dim\n",
    "    y = np.array(labels)\n",
    "    return X, y\n",
    "\n",
    "# Prepare datasets\n",
    "X_train_mel, y_train_mel = prepare_logmel_dataset(df_train, apply_aug = True)\n",
    "X_val_mel,   y_val_mel   = prepare_logmel_dataset(df_val, apply_aug = False)\n",
    "X_testA_mel, y_testA_mel = prepare_logmel_dataset(df_400, apply_aug = False)\n",
    "X_testB_mel, y_testB_mel = prepare_logmel_dataset(df_800, apply_aug = False)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train_mel:\", X_train_mel.shape)\n",
    "print(\"X_val_mel:\", X_val_mel.shape)\n",
    "print(\"X_testA_mel:\", X_testA_mel.shape)\n",
    "print(\"X_testB_mel:\", X_testB_mel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a79acd-eed1-4a51-aadb-a4ae3ab13a00",
   "metadata": {},
   "source": [
    "### 2. Label Encoding / One-Hot Conversion\n",
    "\n",
    "Neural networks require labels to be expressed numerically. This subsection converts categorical song identifiers into integer indices using label encoding. Since the CNN is trained with a softmax output layer and categorical cross-entropy loss, labels must also be represented as one-hot vectors. One-hot encoding ensures that the loss function treats each class independently and that the gradient correctly reflects the probability distribution over the eight songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0580fbe7-fc83-4176-8c78-bc7eb08de017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 8\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(np.concatenate([y_train_mel, y_val_mel, y_testA_mel, y_testB_mel]))\n",
    "\n",
    "y_train_enc = le.transform(y_train_mel)\n",
    "y_val_enc   = le.transform(y_val_mel)\n",
    "y_testA_enc = le.transform(y_testA_mel)\n",
    "y_testB_enc = le.transform(y_testB_mel)\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Num classes:\", num_classes)\n",
    "\n",
    "# One-hot for Keras\n",
    "y_train_cat = to_categorical(y_train_enc, num_classes)\n",
    "y_val_cat   = to_categorical(y_val_enc, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc94a6-bdb5-4a05-81e9-f7f040fcba88",
   "metadata": {},
   "source": [
    "### 3. CNN Architecture\n",
    "\n",
    "This subsection describes the convolutional neural network used for melody classification. CNNs are well suited for audio spectrograms because they capture local time‚Äìfrequency patterns (e.g., pitch transitions, harmonic structures) through convolutional filters. The architecture includes multiple convolutional layers, batch normalization, pooling operations, and dense layers for classification. These components allow the model to learn hierarchical representations of melodic features, progressing from low-level spectral cues to high-level song-specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3e75460-8a8f-4e41-b943-d63354b96b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_4                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_5                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_6                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_7                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ global_average_pooling2d_1           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m1\u001b[0m)          ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)         ‚îÇ             \u001b[38;5;34m320\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_4                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)         ‚îÇ             \u001b[38;5;34m128\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)         ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m32\u001b[0m)         ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m64\u001b[0m)         ‚îÇ          \u001b[38;5;34m18,496\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_5                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m64\u001b[0m)         ‚îÇ             \u001b[38;5;34m256\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m64\u001b[0m)         ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m64\u001b[0m)          ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m128\u001b[0m)         ‚îÇ          \u001b[38;5;34m73,856\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_6                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m128\u001b[0m)         ‚îÇ             \u001b[38;5;34m512\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)                       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m128\u001b[0m)         ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m128\u001b[0m)          ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m256\u001b[0m)          ‚îÇ         \u001b[38;5;34m295,168\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_7                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m256\u001b[0m)          ‚îÇ           \u001b[38;5;34m1,024\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)                       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m256\u001b[0m)          ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)          ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ global_average_pooling2d_1           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             ‚îÇ                             ‚îÇ                 ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 ‚îÇ          \u001b[38;5;34m32,896\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   ‚îÇ           \u001b[38;5;34m1,032\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">423,688</span> (1.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m423,688\u001b[0m (1.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,728</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m422,728\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "def build_cnn(input_shape=(N_MELS, TARGET_FRAMES, 1), num_classes=num_classes):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3,3), padding=\"same\", activation=None)(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3,3), padding=\"same\", activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3,3), padding=\"same\", activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (3,3), padding=\"same\", activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    return model\n",
    "\n",
    "cnn_model = build_cnn()\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f26c01f-e673-47d9-b63b-06deaedd5c19",
   "metadata": {},
   "source": [
    "### 4. Training Stage\n",
    "\n",
    "The training procedure outlines how model parameters are optimized. The CNN is trained using the Adam optimizer, which adapts learning rates based on gradient statistics. Early stopping is applied to prevent overfitting by halting training when validation performance ceases to improve, and learning rate scheduling helps stabilize convergence by reducing the step size once training plateaus. This systematic training strategy ensures efficient optimization and promotes better generalization to unseen humming recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24ba8066-3ffa-4ae4-9e7b-794da1c43aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 - 16s - 792ms/step - accuracy: 0.1344 - loss: 2.4918 - val_accuracy: 0.1250 - val_loss: 5.8493 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "20/20 - 12s - 616ms/step - accuracy: 0.1594 - loss: 2.1565 - val_accuracy: 0.1250 - val_loss: 5.1308 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "20/20 - 12s - 619ms/step - accuracy: 0.1531 - loss: 2.1078 - val_accuracy: 0.1187 - val_loss: 2.7079 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "20/20 - 12s - 594ms/step - accuracy: 0.1141 - loss: 2.1119 - val_accuracy: 0.1250 - val_loss: 2.3716 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "20/20 - 12s - 600ms/step - accuracy: 0.1766 - loss: 2.0616 - val_accuracy: 0.1063 - val_loss: 2.1938 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "20/20 - 12s - 596ms/step - accuracy: 0.1500 - loss: 2.0800 - val_accuracy: 0.1688 - val_loss: 2.0690 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "20/20 - 12s - 602ms/step - accuracy: 0.1797 - loss: 2.0589 - val_accuracy: 0.1875 - val_loss: 2.0643 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "20/20 - 12s - 610ms/step - accuracy: 0.1844 - loss: 2.0237 - val_accuracy: 0.2062 - val_loss: 2.0341 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "20/20 - 12s - 618ms/step - accuracy: 0.1719 - loss: 2.0332 - val_accuracy: 0.1937 - val_loss: 1.9984 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "20/20 - 13s - 639ms/step - accuracy: 0.2000 - loss: 2.0072 - val_accuracy: 0.2562 - val_loss: 1.9974 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "20/20 - 13s - 647ms/step - accuracy: 0.2219 - loss: 1.9880 - val_accuracy: 0.2375 - val_loss: 1.9933 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "20/20 - 12s - 618ms/step - accuracy: 0.2000 - loss: 1.9803 - val_accuracy: 0.3063 - val_loss: 1.9312 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "20/20 - 12s - 614ms/step - accuracy: 0.1969 - loss: 1.9971 - val_accuracy: 0.1688 - val_loss: 1.9888 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "20/20 - 12s - 602ms/step - accuracy: 0.2328 - loss: 1.9503 - val_accuracy: 0.3063 - val_loss: 1.9279 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "20/20 - 12s - 616ms/step - accuracy: 0.2203 - loss: 1.9519 - val_accuracy: 0.2688 - val_loss: 1.9423 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "20/20 - 13s - 665ms/step - accuracy: 0.2641 - loss: 1.9045 - val_accuracy: 0.1813 - val_loss: 1.9810 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "20/20 - 14s - 713ms/step - accuracy: 0.2375 - loss: 1.9066 - val_accuracy: 0.2000 - val_loss: 2.0913 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "20/20 - 14s - 676ms/step - accuracy: 0.2703 - loss: 1.8485 - val_accuracy: 0.2688 - val_loss: 1.8364 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "20/20 - 13s - 642ms/step - accuracy: 0.2719 - loss: 1.8577 - val_accuracy: 0.2562 - val_loss: 1.8757 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "20/20 - 13s - 671ms/step - accuracy: 0.3125 - loss: 1.7787 - val_accuracy: 0.1625 - val_loss: 2.3223 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "20/20 - 13s - 633ms/step - accuracy: 0.3000 - loss: 1.8101 - val_accuracy: 0.2375 - val_loss: 1.7994 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "20/20 - 13s - 633ms/step - accuracy: 0.3328 - loss: 1.7148 - val_accuracy: 0.2250 - val_loss: 2.0322 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "20/20 - 12s - 619ms/step - accuracy: 0.3156 - loss: 1.7291 - val_accuracy: 0.3625 - val_loss: 1.7574 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "20/20 - 13s - 625ms/step - accuracy: 0.3406 - loss: 1.6903 - val_accuracy: 0.2688 - val_loss: 1.9251 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "20/20 - 13s - 635ms/step - accuracy: 0.3359 - loss: 1.6819 - val_accuracy: 0.2812 - val_loss: 1.8945 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 - 13s - 625ms/step - accuracy: 0.3500 - loss: 1.6524 - val_accuracy: 0.1500 - val_loss: 2.9472 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "20/20 - 13s - 628ms/step - accuracy: 0.3844 - loss: 1.6288 - val_accuracy: 0.3438 - val_loss: 1.8682 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "20/20 - 13s - 636ms/step - accuracy: 0.3859 - loss: 1.5665 - val_accuracy: 0.3063 - val_loss: 1.8897 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 - 13s - 658ms/step - accuracy: 0.4359 - loss: 1.4862 - val_accuracy: 0.1813 - val_loss: 2.4937 - learning_rate: 2.5000e-04\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n"
     ]
    }
   ],
   "source": [
    "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    X_train_mel, y_train_cat,\n",
    "    validation_data=(X_val_mel, y_val_cat),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b6094-30ef-4e69-bcca-a8314fcae4d8",
   "metadata": {},
   "source": [
    "### 5. Validation Stage\n",
    "\n",
    "The validation stage evaluates model performance on a hold-out subset of the training dataset (here, 20% of Dataset B). This stage serves multiple purposes: it allows hyperparameter tuning, monitors overfitting during training, and informs early stopping decisions for the CNN. Using a validation set ensures that performance estimates reflect generalisation to unseen data rather than memorization of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dce165c3-a7b3-4ad6-b151-fa414d1350b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (CNN): 0.3625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Validation\n",
    "val_probs = cnn_model.predict(X_val_mel, verbose=0)\n",
    "val_pred_idx = np.argmax(val_probs, axis=1)\n",
    "val_pred_labels = le.inverse_transform(val_pred_idx)\n",
    "val_acc = accuracy_score(y_val_mel, val_pred_labels)\n",
    "print(\"Validation Accuracy (CNN):\", round(val_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9089e-da98-4576-8040-ee3a300e603a",
   "metadata": {},
   "source": [
    "### 6. Testing Stage\n",
    "\n",
    "The testing stage assesses final model generalisation on independent datasets not used during training or validation (Dataset A and Dataset B). This step provides an unbiased measure of how the model performs on novel samples, including potential variations in participant humming styles, recording conditions, or melodic interpretation. Testing on multiple datasets helps evaluate the robustness and scalability of the learned classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b75e0302-118a-4053-a1fb-8d24628642e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test A Accuracy (CNN): 0.36\n",
      "Test B Accuracy (CNN): 0.3538\n"
     ]
    }
   ],
   "source": [
    "# Test A\n",
    "testA_probs = cnn_model.predict(X_testA_mel, verbose=0)\n",
    "testA_pred_idx = np.argmax(testA_probs, axis=1)\n",
    "testA_pred_labels = le.inverse_transform(testA_pred_idx)\n",
    "testA_acc = accuracy_score(y_testA_mel, testA_pred_labels)\n",
    "print(\"Test A Accuracy (CNN):\", round(testA_acc,4))\n",
    "\n",
    "# Test B\n",
    "testB_probs = cnn_model.predict(X_testB_mel, verbose=0)\n",
    "testB_pred_idx = np.argmax(testB_probs, axis=1)\n",
    "testB_pred_labels = le.inverse_transform(testB_pred_idx)\n",
    "testB_acc = accuracy_score(y_testB_mel, testB_pred_labels)\n",
    "print(\"Test B Accuracy (CNN):\", round(testB_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c35a1-1861-43eb-b148-4de0953c24b9",
   "metadata": {},
   "source": [
    "### 7. Secondary Metrics\n",
    "\n",
    "These metrics reveal which songs are frequently confused, the reliability of predictions for each class, and whether the model correctly ranks the true label among its top guesses. Such analyses are crucial for interpreting limitations, identifying patterns of errors, and guiding future improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928678a6-07ef-48e0-bf9b-55008aa1f293",
   "metadata": {},
   "source": [
    "#### 7.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dee9f5b8-bb6e-4e67-81ea-d8bded9e8782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val_mel, val_pred_labels, labels=le.classes_)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"CNN - Confusion Matrix (Validation)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2cc74c-40f2-4713-94e5-4d643a063656",
   "metadata": {},
   "source": [
    "#### 7.2 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e97589be-4a7c-48ea-b0a2-5c6dc560832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report (Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Feeling     0.0000    0.0000    0.0000        20\n",
      "       Friend     0.0000    0.0000    0.0000        20\n",
      "        Happy     0.3158    0.9000    0.4675        20\n",
      "      Married     0.5000    0.1000    0.1667        20\n",
      "  Necessities     0.4186    0.9000    0.5714        20\n",
      "      NewYork     0.3721    0.8000    0.5079        20\n",
      "   RememberMe     0.4000    0.2000    0.2667        20\n",
      "TryEverything     0.0000    0.0000    0.0000        20\n",
      "\n",
      "     accuracy                         0.3625       160\n",
      "    macro avg     0.2508    0.3625    0.2475       160\n",
      " weighted avg     0.2508    0.3625    0.2475       160\n",
      "\n",
      "Macro F1 (Validation): 0.2475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oscar\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\oscar\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\oscar\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report (Validation):\")\n",
    "print(classification_report(y_val_mel, val_pred_labels, digits=4))\n",
    "\n",
    "# Macro F1\n",
    "macro_f1 = f1_score(y_val_mel, val_pred_labels, average=\"macro\")\n",
    "print(\"Macro F1 (Validation):\", round(macro_f1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f965ea6-d314-4365-8892-d690392803f0",
   "metadata": {},
   "source": [
    "#### 7.3 Top-k Accuracy (k = 3 and k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "518fbfb1-d088-4be7-91ab-de32a0e651c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy (Validation): 0.6438\n",
      "Top-5 Accuracy (Validation): 0.8812\n"
     ]
    }
   ],
   "source": [
    "# Top-k aacuracy\n",
    "def top_k_accuracy_labels(y_true, probs, labels, k):\n",
    "    correct = 0\n",
    "    for i in range(len(y_true)):\n",
    "        top_k_idx = np.argsort(probs[i])[::-1][:k]\n",
    "        top_k_labels = labels[top_k_idx]\n",
    "        if y_true[i] in top_k_labels:\n",
    "            correct += 1\n",
    "    return correct / len(y_true)\n",
    "\n",
    "labels_arr = le.classes_\n",
    "print(\"Top-3 Accuracy (Validation):\", round(top_k_accuracy_labels(y_val_mel, val_probs, labels_arr, 3),4))\n",
    "print(\"Top-5 Accuracy (Validation):\", round(top_k_accuracy_labels(y_val_mel, val_probs, labels_arr, 5),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7565bf2-7ead-4eaf-a53a-b2db2bca5de5",
   "metadata": {},
   "source": [
    "### 8. Results Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f8582-8975-49a6-a8de-82d7920ca539",
   "metadata": {},
   "source": [
    "**Overall Performance**\n",
    "\n",
    "The CNN achieves a validation accuracy of 36.25% and similar test accuracies on Dataset A (36%) and Dataset B (35.38%). This shows that the CNN slightly outperforms the classical models (Logistic Regression and Random Forest) on this task, though overall performance remains moderate. The model is able to capture some melodic and harmonic patterns, as evidenced by higher top-3 (64.38%) and top-5 (88.12%) accuracies, indicating that even when the top prediction is incorrect, the true song is often among the top candidates.\n",
    "\n",
    "\n",
    "**Reasons Why Validation Accuracy Is Low**\n",
    "\n",
    "Several factors likely contribute to the relatively low validation accuracy:\n",
    "\n",
    "* Small per-class sample size: With only 16 training samples per song, the CNN cannot fully learn generalizable features across participants.\n",
    "* High variability in humming/whistling: Differences in pitch, tempo, and personal vocal characteristics make classification challenging.\n",
    "* Underfitting / insufficient representation: The CNN may require more data or stronger augmentation to capture the subtle distinctions between songs.\n",
    "* Sparse correct predictions for some classes: Classes like Feeling, Friend, and TryEverything show zero recall, indicating the model struggles with certain songs, likely due to lack of training samples or higher melodic similarity with other classes.\n",
    "\n",
    "**Secondary Metrics Interpretation**\n",
    "\n",
    "* Per-class performance: Certain songs (Happy, Necessities, NewYork) achieve high recall (0.8‚Äì0.9), suggesting the CNN is able to reliably detect a subset of songs with distinctive melodic patterns. Conversely, some songs have zero recall, highlighting imbalance in learnable features across classes.\n",
    "* Macro F1 (0.2475): Reflects the average per-class performance; low value indicates strong class imbalance and poor generalization to harder-to-learn classes.\n",
    "* Top-k accuracy: Top-3 and top-5 accuracies (64.38% and 88.12%) reveal that while the CNN struggles to predict the exact top song, it frequently ranks the correct song among the most probable predictions. This aligns with the musical context where many melodies share similar fragments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea9c05-4367-448b-aa99-65aa7c27e3e8",
   "metadata": {},
   "source": [
    "# 7 Conclusions\n",
    "\n",
    "In this study, we explored the automatic classification of hummed and whistled melodies using three different models: Logistic Regression, Random Forest, and a Convolutional Neural Network (CNN). We implemented consistent preprocessing pipelines, including amplitude normalization, resampling, padding/truncation, and data augmentation and extracted features appropriate for each model (MFCCs for classical models and log-Mel spectrograms for CNN).\n",
    "\n",
    "**Findings**\n",
    "\n",
    "* Classical models (Logistic Regression and Random Forest) achieved moderate test accuracies (~69‚Äì71%) but low validation accuracies (~30%).\n",
    "* The CNN slightly outperformed classical models in validation accuracy (36.25%), and its top-k accuracies demonstrated that it frequently ranks the correct song among the top predictions, even if the top-1 prediction is incorrect.\n",
    "* Overall, all models struggled with songs that had limited or highly variable samples, highlighting the challenges of small datasets and participant variability.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* The dataset is relatively small, which limits the ability of models, especially CNNs, to learn robust representations.\n",
    "* High variability in human humming and whistling introduces noise that classical feature-based models cannot fully capture.\n",
    "* Certain songs were consistently misclassified, indicating possible melodic similarity or insufficient distinguishing features in the input representation.\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "* Increase dataset size, either by collecting more recordings or using advanced data augmentation techniques.\n",
    "* Explore more expressive feature representations, such as pitch contours, chroma features, or learned embeddings.\n",
    "* Consider more advanced architectures for the CNN to better capture temporal dependencies and melodic patterns.\n",
    "* Investigate ensemble approaches combining classical models with neural networks for improved robustness.\n",
    "* Evaluate additional metrics such as top-k accuracy, per-class F1, and confusion patterns to better understand model weaknesses and guide targeted improvements.\n",
    "\n",
    "\n",
    "This work demonstrates the feasibility of automated melody classification from hummed or whistled inputs but also highlights the challenges inherent in small, variable datasets. Future work should focus on expanding the dataset, improving feature representations, and leveraging modern deep learning techniques to enhance model generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64661077-c66e-4dbe-ad94-3ed65d8f62bb",
   "metadata": {},
   "source": [
    "# 8 References\n",
    "\n",
    "* MLEnd Hums and Whistles II Dataset (2025).  \n",
    "  Provided as part of the ECS7020P Mini-Project.\n",
    "  https://github.com/thekmannn/MLEndHW_Sample/raw/main/MLEndHWII_Sample_800.zip\n",
    "\n",
    "* Bishop, C. (2006). *Pattern Recognition and Machine Learning.*  \n",
    "  Springer.  \n",
    "  (Referenced for classical ML models such as k-NN, SVM, and Random Forest.)\n",
    "\n",
    "* TensorFlow and Keras documentation.  \n",
    "  TensorFlow Developers (2023). https://www.tensorflow.org/api_docs\n",
    "\n",
    "* Librosa: Python library for audio analysis.  \n",
    "  McFee et al. (2015). *librosa: Audio and Music Signal Analysis in Python.* https://librosa.org\n",
    "\n",
    "* Pedregosa et al. (2011). *Scikit-learn: Machine Learning in Python.*  \n",
    "  Journal of Machine Learning Research. https://scikit-learn.org\n",
    "\n",
    "* Goodfellow, Bengio & Courville (2016). *Deep Learning.* MIT Press.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fffe900-4d8b-4dae-ac2c-36292fa77888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (Miniconda)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
